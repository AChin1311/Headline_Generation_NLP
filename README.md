# Headline_Generation_NLP
## 1. Problem Formation
Headline generation is within the category of the text summarization. In this project, we would like to modify the current way of headline generation and automatically generate headlines from the text of news articles. Since headlines are terse and convey the most important theme of the input text, it wonâ€™t be appropriate to just select a subset of actual sentences from the original text as a summary. Instead, it should be generated by building the semantic representation of the text and create a summary. 

The model of news headline generation we are trying to improve in this project is the one proposed by Konstantin Lopyrev [1], which adopts an end-to-end encoder-decoder framework as well as utilizes attention mechanism. The encoder and the decoder are each a recurrent neural network. The encoder encodes a source article into a sequence of latent vectors, and the decoder outputs a summary word by word based on the latent vectors. The attention mechanism allows the decoder to attend to different parts of the source. 

##2. Project Plans
We plan to implement a bidirectional RNN to preserve information from both directions. The original RNN model only takes into consideration the current and the previous words to decide values to assign the neurons, while using bidirectional RNN considers also the words that follow. 

We also plan to make improvements on data selection. The original model uses only the first 50 words of a news article to generate the headline. We are going to collect several sentences from each paragraph and/or use pre-trained POS tagging models to remove adjectives.

## 3. Dataset and Evaluation
The ideal dataset for this project would be the English Gigaword [2]. It was used by Lopyrev, however we may need to deal with copyright issues first. Alternative datasets are AP News and Wall Street Journal data [3] and 143 thousands articles from 15 American publications [4]. 

We will evaluate generated news headlines with two metrics: BLEU and ROUGE. In general, BLEU measures how much the words in the machine-generated headlines appeared in the human reference headlines, while ROUGE measures how much the words in the human reference headlines appeared in the machine-generated headlines.
## Reference
[1] Lopyrev, Konstantin. "Generating news headlines with recurrent neural networks." arXiv preprint arXiv:1512.01712(2015).
[2] English Gigaword dataset. https://catalog.ldc.upenn.edu/ldc2003t05.
[3] AP News and Wall Street Journal data. http://boston.lti.cs.cmu.edu/callan/Data/.
[4] 143,000 articles from 15 American publications. https://www.kaggle.com/snapcrack/all-the-news.
